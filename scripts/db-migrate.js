#!/usr/bin/env node
/**
 * Supabase Migration ìë™í™” ì‹œìŠ¤í…œ
 * SQL Editor ì—†ì´ ì™„ì „í•œ ë§ˆì´ê·¸ë ˆì´ì…˜ ê´€ë¦¬
 * ì‚¬ìš©ë²•: node scripts/db-migrate.js <command> [options]
 */

import { createClient } from '@supabase/supabase-js'
import fs from 'fs'
import path from 'path'
import { fileURLToPath } from 'url'
import dotenv from 'dotenv'

const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)

dotenv.config({ path: '.env.local' })

const SUPABASE_URL = process.env.NEXT_PUBLIC_SUPABASE_URL
const SUPABASE_SERVICE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY

if (!SUPABASE_URL || !SUPABASE_SERVICE_KEY) {
  console.error('âŒ í™˜ê²½ë³€ìˆ˜ ì˜¤ë¥˜')
  process.exit(1)
}

const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_KEY, {
  auth: {
    autoRefreshToken: false,
    persistSession: false
  }
})

const MIGRATIONS_DIR = path.join(process.cwd(), 'supabase', 'migrations')

/**
 * ë§ˆì´ê·¸ë ˆì´ì…˜ ë””ë ‰í† ë¦¬ ìƒì„±
 */
function ensureMigrationsDir() {
  if (!fs.existsSync(MIGRATIONS_DIR)) {
    fs.mkdirSync(MIGRATIONS_DIR, { recursive: true })
    console.log(`âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ë””ë ‰í† ë¦¬ ìƒì„±: ${MIGRATIONS_DIR}`)
  }
}

/**
 * íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
 */
function generateTimestamp() {
  const now = new Date()
  return now.toISOString()
    .replace(/[-:]/g, '')
    .replace(/\..+/, '')
    .replace('T', '_')
}

/**
 * ìƒˆ ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼ ìƒì„±
 */
function createMigration(name, content = '') {
  ensureMigrationsDir()
  
  const timestamp = generateTimestamp()
  const filename = `${timestamp}_${name.replace(/\s+/g, '_').toLowerCase()}.sql`
  const filepath = path.join(MIGRATIONS_DIR, filename)
  
  const template = content || `-- Migration: ${name}
-- Created: ${new Date().toISOString()}

BEGIN;

-- Your migration SQL here

COMMIT;
`

  fs.writeFileSync(filepath, template)
  console.log(`âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒì„±: ${filename}`)
  return filepath
}

/**
 * ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼ ëª©ë¡ ì¡°íšŒ
 */
function getMigrations() {
  ensureMigrationsDir()
  
  const files = fs.readdirSync(MIGRATIONS_DIR)
    .filter(file => file.endsWith('.sql'))
    .sort()
  
  return files.map(filename => ({
    filename,
    filepath: path.join(MIGRATIONS_DIR, filename),
    timestamp: filename.split('_')[0],
    name: filename.replace(/^\d+_/, '').replace(/\.sql$/, '')
  }))
}

/**
 * SQL íŒŒì¼ ì‹¤í–‰ (ê°œì„ ëœ ë§ˆì´ê·¸ë ˆì´ì…˜ í•¨ìˆ˜ ì‚¬ìš©)
 */
async function executeSQLFile(filepath) {
  try {
    const content = fs.readFileSync(filepath, 'utf8')
    console.log(`ğŸš€ ì‹¤í–‰ ì¤‘: ${path.basename(filepath)}`)
    
    // execute_migration RPC í•¨ìˆ˜ ì‚¬ìš© (ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ í•œ ë²ˆì— ì‹¤í–‰)
    const { data, error } = await supabase.rpc('execute_migration', {
      migration_sql: content
    })

    if (error) {
      console.error(`âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰ ì˜¤ë¥˜:`, error.message)
      return { success: false, error: error.message }
    }

    if (data && data.status === 'success') {
      console.log(`âœ… ì™„ë£Œ: ${path.basename(filepath)}`)
      console.log(`ğŸ“Š ì‹¤í–‰ ì‹œê°„: ${data.timestamp}`)
      return { success: true }
    } else if (data && data.status === 'error') {
      console.error(`âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜¤ë¥˜: ${data.message}`)
      console.error(`ğŸ” ìƒì„¸ ì •ë³´: ${data.detail}`)
      return { success: false, error: data.message }
    }

    return { success: true }
  } catch (err) {
    console.error(`âŒ íŒŒì¼ ì‹¤í–‰ ì˜¤ë¥˜: ${err.message}`)
    return { success: false, error: err.message }
  }
}

/**
 * ëª¨ë“  ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
 */
async function runMigrations() {
  const migrations = getMigrations()
  
  if (migrations.length === 0) {
    console.log('ğŸ“ ì‹¤í–‰í•  ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.')
    return
  }
  
  console.log(`ğŸš€ ${migrations.length}ê°œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰ ì‹œì‘...`)
  
  for (const migration of migrations) {
    const result = await executeSQLFile(migration.filepath)
    
    if (!result.success) {
      console.error(`âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: ${migration.filename}`)
      console.error(`ì˜¤ë¥˜: ${result.error}`)
      break
    }
  }
  
  console.log('âœ… ëª¨ë“  ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!')
}

/**
 * íŠ¹ì • ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
 */
async function runSpecificMigration(filename) {
  const migrations = getMigrations()
  const migration = migrations.find(m => m.filename.includes(filename))
  
  if (!migration) {
    console.error(`âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${filename}`)
    return
  }
  
  const result = await executeSQLFile(migration.filepath)
  
  if (result.success) {
    console.log(`âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: ${migration.filename}`)
  } else {
    console.error(`âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: ${migration.filename}`)
    console.error(`ì˜¤ë¥˜: ${result.error}`)
  }
}

/**
 * ë§ˆì´ê·¸ë ˆì´ì…˜ ëª©ë¡ í‘œì‹œ
 */
function listMigrations() {
  const migrations = getMigrations()
  
  if (migrations.length === 0) {
    console.log('ğŸ“ ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.')
    return
  }
  
  console.log(`ğŸ“‹ ${migrations.length}ê°œ ë§ˆì´ê·¸ë ˆì´ì…˜ ë°œê²¬:`)
  migrations.forEach((migration, index) => {
    console.log(`  ${index + 1}. ${migration.filename}`)
    console.log(`     ${migration.name}`)
  })
}

/**
 * ëŒ“ê¸€ ì‹œìŠ¤í…œ ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒì„±
 */
function createCommentsMigration() {
  const content = `-- Migration: Comments System with 2-level nesting
-- Created: ${new Date().toISOString()}
-- Features: 2-level nested comments, real-time, RLS

BEGIN;

-- 1. Comments í…Œì´ë¸”ì— ëˆ„ë½ëœ ì»¬ëŸ¼ ì¶”ê°€
ALTER TABLE comments 
ADD COLUMN IF NOT EXISTS parent_comment_id UUID REFERENCES comments(id) ON DELETE CASCADE,
ADD COLUMN IF NOT EXISTS is_deleted BOOLEAN DEFAULT FALSE;

-- 2. ìƒˆë¡œìš´ ì¸ë±ìŠ¤ ìƒì„± (ì„±ëŠ¥ ìµœì í™”)
CREATE INDEX IF NOT EXISTS comments_parent_comment_id_idx ON comments(parent_comment_id);
CREATE INDEX IF NOT EXISTS comments_post_id_created_at_idx ON comments(post_id, created_at DESC);

-- 3. ëŒ“ê¸€ ê¸¸ì´ ì œí•œ ì¶”ê°€
ALTER TABLE comments 
ADD CONSTRAINT IF NOT EXISTS comments_content_length 
CHECK (length(content) >= 1 AND length(content) <= 1000);

-- 4. ëŒ“ê¸€ í†µê³„ ë·° ìƒì„±
DROP VIEW IF EXISTS comment_stats;
CREATE VIEW comment_stats AS
SELECT 
    c.id,
    c.post_id,
    c.user_id,
    c.author_name,
    c.parent_comment_id,
    c.content,
    c.is_deleted,
    c.created_at,
    c.updated_at,
    COALESCE(cl.like_count, 0) as like_count,
    COALESCE(cr.reply_count, 0) as reply_count
FROM comments c
LEFT JOIN (
    SELECT comment_id, COUNT(*) as like_count
    FROM comment_likes
    GROUP BY comment_id
) cl ON c.id = cl.comment_id
LEFT JOIN (
    SELECT parent_comment_id, COUNT(*) as reply_count
    FROM comments
    WHERE parent_comment_id IS NOT NULL AND is_deleted = FALSE
    GROUP BY parent_comment_id
) cr ON c.id = cr.parent_comment_id
WHERE c.is_deleted = FALSE;

-- 5. RLS ì •ì±… í™œì„±í™” ë° ì„¤ì •
ALTER TABLE comments ENABLE ROW LEVEL SECURITY;
ALTER TABLE comment_likes ENABLE ROW LEVEL SECURITY;

-- ê¸°ì¡´ ì •ì±… ì‚­ì œ í›„ ì¬ìƒì„±
DROP POLICY IF EXISTS "Anyone can view comments" ON comments;
DROP POLICY IF EXISTS "Authenticated users can create comments" ON comments;
DROP POLICY IF EXISTS "Users can update own comments" ON comments;

-- ëŒ“ê¸€ ì •ì±… ìƒì„±
CREATE POLICY "Anyone can view comments" ON comments FOR SELECT USING (TRUE);
CREATE POLICY "Authenticated users can create comments" ON comments 
    FOR INSERT WITH CHECK (auth.uid() IS NOT NULL);
CREATE POLICY "Users can update own comments" ON comments 
    FOR UPDATE USING (auth.uid() = user_id);

-- 6. ì¢‹ì•„ìš” ì •ì±… ì„¤ì •
DROP POLICY IF EXISTS "Anyone can view comment likes" ON comment_likes;
DROP POLICY IF EXISTS "Authenticated users can like comments" ON comment_likes;
DROP POLICY IF EXISTS "Users can unlike their own likes" ON comment_likes;

CREATE POLICY "Anyone can view comment likes" ON comment_likes FOR SELECT USING (TRUE);
CREATE POLICY "Authenticated users can like comments" ON comment_likes 
    FOR INSERT WITH CHECK (auth.uid() IS NOT NULL);
CREATE POLICY "Users can unlike their own likes" ON comment_likes 
    FOR DELETE USING (auth.uid() = user_id);

-- 7. ì‹¤ì‹œê°„ ì•Œë¦¼ í•¨ìˆ˜
CREATE OR REPLACE FUNCTION notify_comment_changes()
RETURNS trigger AS $$
BEGIN
    IF TG_OP = 'INSERT' THEN
        PERFORM pg_notify('comment_changes', 
            json_build_object(
                'operation', TG_OP,
                'record', row_to_json(NEW),
                'post_id', NEW.post_id
            )::text
        );
        RETURN NEW;
    ELSIF TG_OP = 'UPDATE' THEN
        PERFORM pg_notify('comment_changes',
            json_build_object(
                'operation', TG_OP,
                'record', row_to_json(NEW),
                'old_record', row_to_json(OLD),
                'post_id', NEW.post_id
            )::text
        );
        RETURN NEW;
    ELSIF TG_OP = 'DELETE' THEN
        PERFORM pg_notify('comment_changes',
            json_build_object(
                'operation', TG_OP,
                'record', row_to_json(OLD),
                'post_id', OLD.post_id
            )::text
        );
        RETURN OLD;
    END IF;
    RETURN NULL;
END;
$$ LANGUAGE plpgsql;

-- 8. íŠ¸ë¦¬ê±° ìƒì„±
DROP TRIGGER IF EXISTS comment_changes_trigger ON comments;
CREATE TRIGGER comment_changes_trigger
    AFTER INSERT OR UPDATE OR DELETE ON comments
    FOR EACH ROW
    EXECUTE FUNCTION notify_comment_changes();

-- 9. updated_at ìë™ ì—…ë°ì´íŠ¸
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

DROP TRIGGER IF EXISTS update_comments_updated_at ON comments;
CREATE TRIGGER update_comments_updated_at
    BEFORE UPDATE ON comments
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();

COMMIT;

-- ì„±ê³µ ë©”ì‹œì§€
SELECT 'âœ… ëŒ“ê¸€ ì‹œìŠ¤í…œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ! 2ë ˆë²¨ ì¤‘ì²©ëŒ“ê¸€ ë° ì‹¤ì‹œê°„ ê¸°ëŠ¥ í™œì„±í™”' as result;`

  return createMigration('comments_system_upgrade', content)
}

/**
 * ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
 */
async function main() {
  const args = process.argv.slice(2)
  const command = args[0]
  
  switch (command) {
    case 'create':
      if (args.length < 2) {
        console.error('âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì´ë¦„ì´ í•„ìš”í•©ë‹ˆë‹¤')
        console.log('ì‚¬ìš©ë²•: node scripts/db-migrate.js create "migration_name"')
        return
      }
      createMigration(args[1])
      break
      
    case 'run':
      if (args.length > 1) {
        await runSpecificMigration(args[1])
      } else {
        await runMigrations()
      }
      break
      
    case 'list':
      listMigrations()
      break
      
    case 'comments':
      const filepath = createCommentsMigration()
      console.log(`âœ… ëŒ“ê¸€ ì‹œìŠ¤í…œ ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒì„±: ${path.basename(filepath)}`)
      console.log('ì‹¤í–‰í•˜ë ¤ë©´: node scripts/db-migrate.js run comments')
      break
      
    default:
      console.log(`
ğŸ”„ Supabase Migration ê´€ë¦¬ ë„êµ¬

ëª…ë ¹ì–´:
  create <name>     ìƒˆ ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒì„±
  run [filename]    ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰ (íŒŒì¼ëª… ì—†ìœ¼ë©´ ëª¨ë‘ ì‹¤í–‰)
  list             ë§ˆì´ê·¸ë ˆì´ì…˜ ëª©ë¡ ë³´ê¸°
  comments         ëŒ“ê¸€ ì‹œìŠ¤í…œ ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒì„±

ì˜ˆì‹œ:
  node scripts/db-migrate.js create "add_user_profiles"
  node scripts/db-migrate.js run
  node scripts/db-migrate.js run comments
  node scripts/db-migrate.js comments
`)
  }
}

// ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ
if (import.meta.url === `file://${process.argv[1]}`) {
  main().catch(console.error)
}

export { createMigration, runMigrations, executeSQLFile }